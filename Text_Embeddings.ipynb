{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Text_Embeddings",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliikhwan99/Text_Embeddings/blob/main/Text_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phoneme Embeddings"
      ],
      "metadata": {
        "id": "tri3tjwq1PJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install phonemizer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:27:50.564548Z",
          "iopub.execute_input": "2025-04-25T16:27:50.565124Z",
          "iopub.status.idle": "2025-04-25T16:27:58.18656Z",
          "shell.execute_reply.started": "2025-04-25T16:27:50.5651Z",
          "shell.execute_reply": "2025-04-25T16:27:58.185631Z"
        },
        "id": "C-mmkmFL1PJD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Morphology Embeddings"
      ],
      "metadata": {
        "id": "AtomjWY41PJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install morfessor\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:27:58.188254Z",
          "iopub.execute_input": "2025-04-25T16:27:58.18858Z",
          "iopub.status.idle": "2025-04-25T16:28:01.289151Z",
          "shell.execute_reply.started": "2025-04-25T16:27:58.188558Z",
          "shell.execute_reply": "2025-04-25T16:28:01.288245Z"
        },
        "id": "J-_ixTJb1PJE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment set"
      ],
      "metadata": {
        "id": "uENyty1L1PJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install phonemizer morfessor\n",
        "!apt-get install espeak-ng\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:01.290392Z",
          "iopub.execute_input": "2025-04-25T16:28:01.290707Z",
          "iopub.status.idle": "2025-04-25T16:28:13.732537Z",
          "shell.execute_reply.started": "2025-04-25T16:28:01.290675Z",
          "shell.execute_reply": "2025-04-25T16:28:13.73179Z"
        },
        "id": "lF4A4zDi1PJF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined Embedding Layer"
      ],
      "metadata": {
        "id": "tBMxaJB51PJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Example values (replace with actual numbers from your dataset)\n",
        "num_phonemes = 100  # Adjust based on how many unique phonemes you have\n",
        "num_morphs = 100    # Adjust based on your morph units\n",
        "num_labels = 3      # E.g., 3 classes: Standard Malay, Sabah dialect, Code-switch\n",
        "\n",
        "class CustomBertWithPhonemeMorph(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.phoneme_emb = nn.Embedding(num_phonemes, 768)\n",
        "        self.morph_emb = nn.Embedding(num_morphs, 768)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, phoneme_ids, morph_ids, attention_mask=None):\n",
        "        # [batch_size, seq_len, emb_dim]\n",
        "        phoneme_vec = self.phoneme_emb(phoneme_ids).mean(dim=2)  # Mean pooling over morph units\n",
        "        morph_vec = self.morph_emb(morph_ids).mean(dim=2)\n",
        "\n",
        "        # BERT output\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]  # [CLS] token representation\n",
        "\n",
        "        # Combine embeddings\n",
        "        combined = cls_emb + phoneme_vec[:, 0, :] + morph_vec[:, 0, :]  # Keep batch-first\n",
        "        logits = self.classifier(self.dropout(combined))\n",
        "        return logits\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:13.734695Z",
          "iopub.execute_input": "2025-04-25T16:28:13.735158Z",
          "iopub.status.idle": "2025-04-25T16:28:13.741956Z",
          "shell.execute_reply.started": "2025-04-25T16:28:13.735134Z",
          "shell.execute_reply": "2025-04-25T16:28:13.741332Z"
        },
        "id": "YNUjIQfy1PJF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "3y9LXAep1PJG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -----TEST----------"
      ],
      "metadata": {
        "id": "i1urnw5o1PJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Dummy Test Dataset"
      ],
      "metadata": {
        "id": "AYLqW-pg1PJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated text samples\n",
        "texts = [\n",
        "    \"Saya pergi ke pasar\",                          # Standard Malay\n",
        "    \"Aku mau pigi kedai bah\",                       # Sabah dialect\n",
        "    \"Saya want to buy makanan from kedai\"           # Code-switched Malay-English\n",
        "]\n",
        "\n",
        "# Fake labels for classification: 0 = Malay, 1 = Dialect, 2 = Code-Switch\n",
        "labels = [0, 1, 2]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:13.742707Z",
          "iopub.execute_input": "2025-04-25T16:28:13.74291Z",
          "iopub.status.idle": "2025-04-25T16:28:13.757632Z",
          "shell.execute_reply.started": "2025-04-25T16:28:13.742887Z",
          "shell.execute_reply": "2025-04-25T16:28:13.756944Z"
        },
        "id": "G3iBufjc1PJG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Step 2: Tokenizer"
      ],
      "metadata": {
        "id": "6jNYGTDk1PJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:13.758307Z",
          "iopub.execute_input": "2025-04-25T16:28:13.75856Z",
          "iopub.status.idle": "2025-04-25T16:28:14.102177Z",
          "shell.execute_reply.started": "2025-04-25T16:28:13.758539Z",
          "shell.execute_reply": "2025-04-25T16:28:14.101611Z"
        },
        "id": "ilLPB0I51PJH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Fake Phoneme & Morph IDs"
      ],
      "metadata": {
        "id": "V6bTzZGd1PJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "batch_size, seq_len = inputs['input_ids'].shape\n",
        "\n",
        "# Randomly simulate phoneme and morph IDs (normally derived from actual phoneme/morph analyzers)\n",
        "phoneme_ids = torch.randint(0, 100, (batch_size, seq_len, 5))  # 5 phoneme units per word\n",
        "morph_ids = torch.randint(0, 100, (batch_size, seq_len, 3))    # 3 morphemes per word\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:14.102789Z",
          "iopub.execute_input": "2025-04-25T16:28:14.102968Z",
          "iopub.status.idle": "2025-04-25T16:28:14.108662Z",
          "shell.execute_reply.started": "2025-04-25T16:28:14.102954Z",
          "shell.execute_reply": "2025-04-25T16:28:14.108057Z"
        },
        "id": "JG94FfDd1PJH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Define Models"
      ],
      "metadata": {
        "id": "8wh_zDlQ1PJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.classifier = nn.Linear(768, 3)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]\n",
        "        return self.classifier(cls_emb)\n",
        "\n",
        "baseline_model = BaselineModel()\n",
        "custom_model = CustomBertWithPhonemeMorph()  # From earlier cell\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:14.109438Z",
          "iopub.execute_input": "2025-04-25T16:28:14.11017Z",
          "iopub.status.idle": "2025-04-25T16:28:14.537105Z",
          "shell.execute_reply.started": "2025-04-25T16:28:14.110145Z",
          "shell.execute_reply": "2025-04-25T16:28:14.536326Z"
        },
        "id": "xgf3-ZDE1PJH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Forward Pass & Comparison"
      ],
      "metadata": {
        "id": "GTcV-oWq1PJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass with baseline\n",
        "with torch.no_grad():\n",
        "    baseline_logits = baseline_model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "\n",
        "# Forward pass with phoneme+morph model\n",
        "with torch.no_grad():\n",
        "    advanced_logits = custom_model(\n",
        "        input_ids=inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        phoneme_ids=phoneme_ids,\n",
        "        morph_ids=morph_ids\n",
        "    )\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:14.537975Z",
          "iopub.execute_input": "2025-04-25T16:28:14.538259Z",
          "iopub.status.idle": "2025-04-25T16:28:14.750382Z",
          "shell.execute_reply.started": "2025-04-25T16:28:14.538234Z",
          "shell.execute_reply": "2025-04-25T16:28:14.749556Z"
        },
        "id": "MiAX9Y7v1PJH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Output Predictions"
      ],
      "metadata": {
        "id": "QqHWrrAX1PJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "baseline_preds = torch.argmax(F.softmax(baseline_logits, dim=1), dim=1)\n",
        "advanced_preds = torch.argmax(F.softmax(advanced_logits, dim=1), dim=1)\n",
        "\n",
        "print(\"Ground Truth:\", labels)\n",
        "print(\"Baseline Predictions:\", baseline_preds.tolist())\n",
        "print(\"Phoneme+Morph Predictions:\", advanced_preds.tolist())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:14.752972Z",
          "iopub.execute_input": "2025-04-25T16:28:14.753553Z",
          "iopub.status.idle": "2025-04-25T16:28:14.758732Z",
          "shell.execute_reply.started": "2025-04-25T16:28:14.753534Z",
          "shell.execute_reply": "2025-04-25T16:28:14.758041Z"
        },
        "id": "TP8yoNtx1PJH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "2BFaq18E1PJI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 2"
      ],
      "metadata": {
        "id": "QiVDQMHz1PJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:14.759506Z",
          "iopub.execute_input": "2025-04-25T16:28:14.760218Z",
          "iopub.status.idle": "2025-04-25T16:28:14.771012Z",
          "shell.execute_reply.started": "2025-04-25T16:28:14.760197Z",
          "shell.execute_reply": "2025-04-25T16:28:14.770394Z"
        },
        "id": "Z78VrHOk1PJI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# phoneme and morph embeddings"
      ],
      "metadata": {
        "id": "Jdj9llnc1PJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_phonemes = 50\n",
        "num_morphs = 100\n",
        "num_labels = 2  # Changed from 3 → now only Kelantanese and Code-switch\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:14.771761Z",
          "iopub.execute_input": "2025-04-25T16:28:14.772516Z",
          "iopub.status.idle": "2025-04-25T16:28:14.783463Z",
          "shell.execute_reply.started": "2025-04-25T16:28:14.772493Z",
          "shell.execute_reply": "2025-04-25T16:28:14.782631Z"
        },
        "id": "eueU3q9b1PJI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBertWithPhonemeMorph(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.phoneme_emb = nn.Embedding(num_phonemes, 768)\n",
        "        self.morph_emb = nn.Embedding(num_morphs, 768)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, num_labels)  # ✅ changed to 2\n",
        "\n",
        "    def forward(self, input_ids, phoneme_ids, morph_ids, attention_mask=None):\n",
        "        phoneme_vec = self.phoneme_emb(phoneme_ids).mean(dim=2)\n",
        "        morph_vec = self.morph_emb(morph_ids).mean(dim=2)\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]\n",
        "        combined = cls_emb + phoneme_vec[:, 0, :] + morph_vec[:, 0, :]\n",
        "        logits = self.classifier(self.dropout(combined))\n",
        "        return logits\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:14.78417Z",
          "iopub.execute_input": "2025-04-25T16:28:14.784426Z",
          "iopub.status.idle": "2025-04-25T16:28:14.796027Z",
          "shell.execute_reply.started": "2025-04-25T16:28:14.784405Z",
          "shell.execute_reply": "2025-04-25T16:28:14.79549Z"
        },
        "id": "rXBMq2Bz1PJI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "texts = [\n",
        "    \"Kawe nok gi kedai jap\",              # Kelantanese\n",
        "    \"Demo makan gapo pagi tadi?\",\n",
        "    \"Ore tu dok gi kerja lagi\",\n",
        "    \"Mu buat gapo situ?\",\n",
        "    \"Bakpo demo lambat sangat?\",\n",
        "    \"I tengah buat kerja rumah sekarang\",      # Code-switch\n",
        "    \"You nak makan sini or tapau?\",\n",
        "    \"Boss suruh I settle that document cepat\",\n",
        "    \"Dia tengah belajar untuk test tomorrow\",\n",
        "    \"You boleh start dulu, I datang later\"\n",
        "]\n",
        "\n",
        "original_labels = [1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n",
        "\n",
        "# ✅ Normalize labels: 1 → 0 (Kelantanese), 2 → 1 (Code-switch)\n",
        "labels = [0 if l == 1 else 1 for l in original_labels]\n",
        "\n",
        "# Tokenize input text\n",
        "encodings = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "input_ids = encodings['input_ids']\n",
        "attention_mask = encodings['attention_mask']\n",
        "batch_size, seq_len = input_ids.shape\n",
        "\n",
        "# Simulated phoneme and morph IDs\n",
        "phoneme_ids = torch.randint(0, num_phonemes, (batch_size, seq_len, 5))\n",
        "morph_ids = torch.randint(0, num_morphs, (batch_size, seq_len, 5))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:14.796809Z",
          "iopub.execute_input": "2025-04-25T16:28:14.797061Z",
          "iopub.status.idle": "2025-04-25T16:28:15.143711Z",
          "shell.execute_reply.started": "2025-04-25T16:28:14.797037Z",
          "shell.execute_reply": "2025-04-25T16:28:15.142836Z"
        },
        "id": "SoqCAlbg1PJI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomBertWithPhonemeMorph()\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(input_ids, phoneme_ids, morph_ids, attention_mask=attention_mask)\n",
        "    predictions = torch.argmax(logits, dim=1)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:15.144602Z",
          "iopub.execute_input": "2025-04-25T16:28:15.144892Z",
          "iopub.status.idle": "2025-04-25T16:28:15.571067Z",
          "shell.execute_reply.started": "2025-04-25T16:28:15.144866Z",
          "shell.execute_reply": "2025-04-25T16:28:15.570252Z"
        },
        "id": "d_Olh1q01PJI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predictions:\", predictions.tolist())\n",
        "print(\"Ground Truth:\", labels)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(labels, predictions.tolist(), target_names=[\"Kelantanese\", \"Code-switch\"]))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:15.571895Z",
          "iopub.execute_input": "2025-04-25T16:28:15.572159Z",
          "iopub.status.idle": "2025-04-25T16:28:15.587163Z",
          "shell.execute_reply.started": "2025-04-25T16:28:15.572136Z",
          "shell.execute_reply": "2025-04-25T16:28:15.586442Z"
        },
        "id": "ukdX_40K1PJJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standard Bert text embeddings"
      ],
      "metadata": {
        "id": "FmUjrBmF1PJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineBertClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]\n",
        "        logits = self.classifier(self.dropout(cls_emb))\n",
        "        return logits\n",
        "\n",
        "# Run baseline\n",
        "baseline_model = BaselineBertClassifier()\n",
        "baseline_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    baseline_logits = baseline_model(input_ids, attention_mask=attention_mask)\n",
        "    baseline_preds = torch.argmax(baseline_logits, dim=1)\n",
        "\n",
        "print(\"\\nBaseline Predictions:\", baseline_preds.tolist())\n",
        "print(classification_report(labels, baseline_preds.tolist(), target_names=[\"Kelantanese\", \"Code-switch\"]))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:15.588421Z",
          "iopub.execute_input": "2025-04-25T16:28:15.588831Z",
          "iopub.status.idle": "2025-04-25T16:28:15.98883Z",
          "shell.execute_reply.started": "2025-04-25T16:28:15.588806Z",
          "shell.execute_reply": "2025-04-25T16:28:15.988015Z"
        },
        "id": "EEIE8axd1PJJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST 3"
      ],
      "metadata": {
        "id": "DyektFcA1PJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 1. Define texts and labels\n",
        "texts = [\n",
        "    \"Kawe nok gi kedai jap\",  # Kelantanese\n",
        "    \"Demo makan gapo pagi tadi?\",\n",
        "    \"Ore tu dok gi kerja lagi\",\n",
        "    \"Mu buat gapo situ?\",\n",
        "    \"Bakpo demo lambat sangat?\",\n",
        "    \"I tengah buat kerja rumah sekarang\",  # Code-switch\n",
        "    \"You nak makan sini or tapau?\",\n",
        "    \"Boss suruh I settle that document cepat\",\n",
        "    \"Dia tengah belajar untuk test tomorrow\",\n",
        "    \"You boleh start dulu, I datang later\"\n",
        "]\n",
        "labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # 0 = Kelantanese, 1 = Code-switch\n",
        "\n",
        "# 2. Phoneme and Morph Vocabularies\n",
        "phoneme_vocab = {ph: idx for idx, ph in enumerate([\"k\", \"a\", \"w\", \"e\", \"n\", \"o\", \"g\", \"i\", \"d\", \"m\", \"p\", \"b\", \"s\", \"y\", \"u\", \"r\", \"t\", \"h\", \"l\", \"j\"])}\n",
        "morph_vocab = {m: idx for idx, m in enumerate([\"ka\", \"we\", \"nok\", \"gi\", \"kedai\", \"jap\", \"you\", \"makan\", \"rumah\", \"buat\", \"kerja\", \"settle\", \"cepat\", \"test\", \"tomorrow\"])}\n",
        "\n",
        "# Save dummy vector files for phoneme and morph\n",
        "def save_dummy_vec(path, vocab):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for token in vocab:\n",
        "            vec = \" \".join([\"0.01\"] * 768)  # dummy small values\n",
        "            f.write(f\"{token} {vec}\\n\")\n",
        "\n",
        "save_dummy_vec(\"phoneme.vec\", phoneme_vocab)\n",
        "save_dummy_vec(\"morph.vec\", morph_vocab)\n",
        "\n",
        "# 3. Tokenization and Mapping\n",
        "def tokenize_and_map(texts, tokenizer, phoneme_vocab, morph_vocab, max_len=20):\n",
        "    input_ids, attention_masks = [], []\n",
        "    phoneme_lists, morph_lists = [], []\n",
        "\n",
        "    max_word_phonemes = 1  # initialize max phonemes per word\n",
        "\n",
        "    # First pass: gather phoneme and morph IDs\n",
        "    for text in texts:\n",
        "        phonemes = [[phoneme_vocab.get(c, 0) for c in word] for word in text.split()]\n",
        "        morphs = [[morph_vocab.get(word.lower(), 0)] for word in text.split()]\n",
        "        phoneme_lists.append(phonemes)\n",
        "        morph_lists.append(morphs)\n",
        "        max_word_phonemes = max(max_word_phonemes, max((len(p) for p in phonemes), default=1))\n",
        "\n",
        "    phoneme_ids, morph_ids = [], []\n",
        "\n",
        "    for text, phonemes, morphs in zip(texts, phoneme_lists, morph_lists):\n",
        "        encoding = tokenizer(text, max_length=max_len, padding='max_length', truncation=True, return_tensors='pt')\n",
        "        input_ids.append(encoding['input_ids'][0])\n",
        "        attention_masks.append(encoding['attention_mask'][0])\n",
        "\n",
        "        # Padded tensors\n",
        "        phoneme_tensor = torch.zeros(max_len, max_word_phonemes, dtype=torch.long)\n",
        "        morph_tensor = torch.zeros(max_len, 1, dtype=torch.long)\n",
        "\n",
        "        for i, (ph, mo) in enumerate(zip(phonemes, morphs)):\n",
        "            if i < max_len:\n",
        "                phoneme_tensor[i, :len(ph)] = torch.tensor(ph)\n",
        "                morph_tensor[i, 0] = mo[0]\n",
        "\n",
        "        phoneme_ids.append(phoneme_tensor)\n",
        "        morph_ids.append(morph_tensor)\n",
        "\n",
        "    return (\n",
        "        torch.stack(input_ids),\n",
        "        torch.stack(attention_masks),\n",
        "        torch.stack(phoneme_ids),\n",
        "        torch.stack(morph_ids),\n",
        "    )\n",
        "\n",
        "# Initialize Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Tokenize and Map\n",
        "input_ids, attention_masks, phoneme_ids, morph_ids = tokenize_and_map(texts, tokenizer, phoneme_vocab, morph_vocab)\n",
        "\n",
        "# 4. MultiModalEncoder Model\n",
        "class MultiModalEncoder(nn.Module):\n",
        "    def __init__(self, bert_model_name, phoneme_vocab_size, morph_vocab_size, phoneme_dim=16, morph_dim=8):\n",
        "        super(MultiModalEncoder, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.bert_hidden_size = self.bert.config.hidden_size\n",
        "\n",
        "        # Embed phonemes and morph features\n",
        "        self.phoneme_emb = nn.Embedding(phoneme_vocab_size, phoneme_dim)\n",
        "        self.morph_emb = nn.Embedding(morph_vocab_size, morph_dim)\n",
        "\n",
        "        # Combine BERT output + mean-pooled phoneme + morph embedding\n",
        "        self.linear = nn.Linear(self.bert_hidden_size + phoneme_dim + morph_dim, 128)\n",
        "        self.classifier = nn.Linear(128, 2)  # Binary classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, phoneme_ids, morph_ids):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        bert_cls = bert_output.last_hidden_state[:, 0, :]  # [CLS] token representation\n",
        "\n",
        "        # Pool phoneme features: mean over each word's phoneme sequence\n",
        "        phoneme_embs = self.phoneme_emb(phoneme_ids)  # (B, T, P, D)\n",
        "        phoneme_mean = phoneme_embs.mean(dim=2)       # (B, T, D)\n",
        "\n",
        "        # Also take morph embedding (B, T, D) → mean across tokens\n",
        "        morph_embs = self.morph_emb(morph_ids.squeeze(-1))  # (B, T, D)\n",
        "\n",
        "        # For simplicity, take mean over token dim to get (B, D) representations\n",
        "        phoneme_feat = phoneme_mean.mean(dim=1)\n",
        "        morph_feat = morph_embs.mean(dim=1)\n",
        "\n",
        "        # Concatenate all features\n",
        "        concat = torch.cat([bert_cls, phoneme_feat, morph_feat], dim=1)\n",
        "        x = self.linear(concat)\n",
        "        x = torch.relu(x)\n",
        "        out = self.classifier(x)\n",
        "        return out\n",
        "\n",
        "# 5. Initialize the Model\n",
        "phoneme_vocab_size = len(phoneme_vocab)\n",
        "morph_vocab_size = len(morph_vocab)\n",
        "\n",
        "model = MultiModalEncoder(\n",
        "    bert_model_name='bert-base-multilingual-cased',\n",
        "    phoneme_vocab_size=phoneme_vocab_size,\n",
        "    morph_vocab_size=morph_vocab_size\n",
        ")\n",
        "\n",
        "model.eval()  # for inference\n",
        "\n",
        "# 6. Inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_masks, phoneme_ids, morph_ids)\n",
        "    predictions = torch.argmax(outputs, dim=1)\n",
        "    print(\"Predictions:\", predictions)\n",
        "\n",
        "# 7. Probability Calculation\n",
        "probs = torch.softmax(outputs, dim=1)\n",
        "print(\"Probabilities:\", probs)\n",
        "\n",
        "# 8. Dataset Class\n",
        "class MultimodalTextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, phoneme_vocab, morph_vocab, max_len=20):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.phoneme_vocab = phoneme_vocab\n",
        "        self.morph_vocab = morph_vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "        (\n",
        "            self.input_ids,\n",
        "            self.attention_masks,\n",
        "            self.phoneme_ids,\n",
        "            self.morph_ids,\n",
        "        ) = tokenize_and_map(texts, tokenizer, phoneme_vocab, morph_vocab, max_len=max_len)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.input_ids[idx],\n",
        "            self.attention_masks[idx],\n",
        "            self.phoneme_ids[idx],\n",
        "            self.morph_ids[idx],\n",
        "            torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:15.989719Z",
          "iopub.execute_input": "2025-04-25T16:28:15.990019Z",
          "iopub.status.idle": "2025-04-25T16:28:16.854315Z",
          "shell.execute_reply.started": "2025-04-25T16:28:15.989986Z",
          "shell.execute_reply": "2025-04-25T16:28:16.853574Z"
        },
        "id": "xQmGWAqu1PJJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert predictions and labels to numpy arrays\n",
        "predictions_np = predictions.cpu().numpy()\n",
        "labels_np = torch.tensor(labels).cpu().numpy()\n",
        "\n",
        "# Generate and print classification report\n",
        "report = classification_report(labels_np, predictions_np, target_names=['Kelantanese', 'Code-switch'])\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(labels_np, predictions_np)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Kelantanese', 'Code-switch'], yticklabels=['Kelantanese', 'Code-switch'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:16.85516Z",
          "iopub.execute_input": "2025-04-25T16:28:16.855495Z",
          "iopub.status.idle": "2025-04-25T16:28:17.017636Z",
          "shell.execute_reply.started": "2025-04-25T16:28:16.855467Z",
          "shell.execute_reply": "2025-04-25T16:28:17.016947Z"
        },
        "id": "OFFw26h_1PJK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UhcON70G1PJK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traslation Task"
      ],
      "metadata": {
        "id": "6_GrRU2r1PJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet sacrebleu\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:17.018452Z",
          "iopub.execute_input": "2025-04-25T16:28:17.018725Z",
          "iopub.status.idle": "2025-04-25T16:28:20.439143Z",
          "shell.execute_reply.started": "2025-04-25T16:28:17.018701Z",
          "shell.execute_reply": "2025-04-25T16:28:20.438463Z"
        },
        "id": "BeBC43KD1PJK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:20.440356Z",
          "iopub.execute_input": "2025-04-25T16:28:20.440982Z",
          "iopub.status.idle": "2025-04-25T16:28:23.374689Z",
          "shell.execute_reply.started": "2025-04-25T16:28:20.440957Z",
          "shell.execute_reply": "2025-04-25T16:28:23.37377Z"
        },
        "id": "y9sSuJgh1PJO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import sacrebleu\n",
        "import re\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:23.375852Z",
          "iopub.execute_input": "2025-04-25T16:28:23.376161Z",
          "iopub.status.idle": "2025-04-25T16:28:23.472521Z",
          "shell.execute_reply.started": "2025-04-25T16:28:23.376125Z",
          "shell.execute_reply": "2025-04-25T16:28:23.472006Z"
        },
        "id": "wa7K5oKw1PJO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample paired dataset (Kelantanese ↔ Code-Switch)\n",
        "data_pairs = [\n",
        "    (\"Demo nok gi mano?\", \"Where are you going?\"),\n",
        "    (\"Kito make nasi tadi.\", \"We ate rice earlier.\"),\n",
        "    (\"Mu buat gapo situ?\", \"What are you doing there?\"),\n",
        "    (\"Tok sir la gi sanung.\", \"Don't go there.\"),\n",
        "    (\"Bakpo mu diam jah?\", \"Why are you so quiet?\"),\n",
        "    (\"I saw dia dekat pasar.\", \"I saw her at the market.\"),\n",
        "    (\"He already balik rumah.\", \"He already went home.\"),\n",
        "    (\"Dia suka makan nasi lemak.\", \"She loves eating nasi lemak.\"),\n",
        "    (\"Jom kita pergi tengok movie.\", \"Let's go watch a movie.\"),\n",
        "    (\"They selalu datang lambat.\", \"They always come late.\")\n",
        "]\n",
        "\n",
        "# Split to train/test\n",
        "train_data, test_data = train_test_split(data_pairs, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:23.473251Z",
          "iopub.execute_input": "2025-04-25T16:28:23.47411Z",
          "iopub.status.idle": "2025-04-25T16:28:23.479677Z",
          "shell.execute_reply.started": "2025-04-25T16:28:23.474091Z",
          "shell.execute_reply": "2025-04-25T16:28:23.478998Z"
        },
        "id": "K71EQ25t1PJO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text.lower())\n",
        "    return text.strip().split()\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, texts, min_freq=1):\n",
        "        tokens = [token for text in texts for token in tokenize(text)]\n",
        "        counter = Counter(tokens)\n",
        "        self.itos = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"] + [word for word, freq in counter.items() if freq >= min_freq]\n",
        "        self.stoi = {word: idx for idx, word in enumerate(self.itos)}\n",
        "\n",
        "    def encode(self, text, max_len=20):\n",
        "        tokens = [\"<sos>\"] + tokenize(text) + [\"<eos>\"]\n",
        "        token_ids = [self.stoi.get(t, self.stoi[\"<unk>\"]) for t in tokens]\n",
        "        return token_ids[:max_len] + [self.stoi[\"<pad>\"]] * (max_len - len(token_ids))\n",
        "\n",
        "    def decode(self, ids):\n",
        "        return \" \".join([self.itos[i] for i in ids if self.itos[i] not in [\"<sos>\", \"<eos>\", \"<pad>\"]])\n",
        "\n",
        "# Build vocab from both sides\n",
        "src_vocab = Vocab([src for src, _ in train_data])\n",
        "tgt_vocab = Vocab([tgt for _, tgt in train_data])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:23.480644Z",
          "iopub.execute_input": "2025-04-25T16:28:23.481205Z",
          "iopub.status.idle": "2025-04-25T16:28:23.494766Z",
          "shell.execute_reply.started": "2025-04-25T16:28:23.481186Z",
          "shell.execute_reply": "2025-04-25T16:28:23.494126Z"
        },
        "id": "D_mDFNag1PJO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, pairs, src_vocab, tgt_vocab):\n",
        "        self.pairs = pairs\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src, tgt = self.pairs[idx]\n",
        "        return (\n",
        "            torch.tensor(self.src_vocab.encode(src), dtype=torch.long),\n",
        "            torch.tensor(self.tgt_vocab.encode(tgt), dtype=torch.long)\n",
        "        )\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    return torch.stack(src_batch), torch.stack(tgt_batch)\n",
        "\n",
        "train_loader = DataLoader(TranslationDataset(train_data, src_vocab, tgt_vocab), batch_size=2, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(TranslationDataset(test_data, src_vocab, tgt_vocab), batch_size=1, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:23.495589Z",
          "iopub.execute_input": "2025-04-25T16:28:23.495813Z",
          "iopub.status.idle": "2025-04-25T16:28:23.510481Z",
          "shell.execute_reply.started": "2025-04-25T16:28:23.495793Z",
          "shell.execute_reply": "2025-04-25T16:28:23.509775Z"
        },
        "id": "Z8rHZKJi1PJO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTransformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=128, nhead=4, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.src_embed = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embed = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_layers, num_layers)\n",
        "        self.out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src = self.src_embed(src).permute(1, 0, 2)  # (S, N, E)\n",
        "        tgt = self.tgt_embed(tgt).permute(1, 0, 2)\n",
        "        out = self.transformer(src, tgt)\n",
        "        return self.out(out).permute(1, 0, 2)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:23.511182Z",
          "iopub.execute_input": "2025-04-25T16:28:23.511479Z",
          "iopub.status.idle": "2025-04-25T16:28:23.522402Z",
          "shell.execute_reply.started": "2025-04-25T16:28:23.511454Z",
          "shell.execute_reply": "2025-04-25T16:28:23.521786Z"
        },
        "id": "uQ7bc8Wy1PJO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -----------"
      ],
      "metadata": {
        "id": "XtM4u9Hp1PJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleTransformer(len(src_vocab.itos), len(tgt_vocab.itos)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=src_vocab.stoi[\"<pad>\"])\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    for src, tgt in train_loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_output = tgt[:, 1:]\n",
        "\n",
        "        logits = model(src, tgt_input)\n",
        "        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:23.523073Z",
          "iopub.execute_input": "2025-04-25T16:28:23.523699Z",
          "iopub.status.idle": "2025-04-25T16:28:24.535158Z",
          "shell.execute_reply.started": "2025-04-25T16:28:23.523682Z",
          "shell.execute_reply": "2025-04-25T16:28:24.534552Z"
        },
        "id": "0W6YHXjQ1PJP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sacrebleu  # This replaces torchtext for BLEU score computation\n",
        "\n",
        "def generate_translation(model, src, src_vocab, tgt_vocab, max_len=50, beam_width=3, device=torch.device(\"cuda\")):\n",
        "    model.eval()\n",
        "    # Start of sentence token\n",
        "    sos_token = tgt_vocab.stoi[\"<sos>\"]\n",
        "    eos_token = tgt_vocab.stoi[\"<eos>\"]\n",
        "\n",
        "    # Initialize beam search\n",
        "    beams = [(torch.tensor([sos_token]).to(device), 0)]  # Each beam stores a sequence and its score\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        new_beams = []\n",
        "        for seq, score in beams:\n",
        "            # Pass current sequence through model\n",
        "            logits = model(src, seq.unsqueeze(0))  # Assuming model outputs logits (batch_size, seq_len, vocab_size)\n",
        "            probs = F.softmax(logits[:, -1, :], dim=-1)  # Get probability distribution for next token\n",
        "\n",
        "            top_k_probs, top_k_indices = probs.topk(beam_width, dim=-1)  # Get top-k tokens and their probabilities\n",
        "\n",
        "            for prob, idx in zip(top_k_probs[0], top_k_indices[0]):\n",
        "                new_seq = torch.cat([seq, idx.unsqueeze(0)])\n",
        "                new_score = score - torch.log(prob)  # Accumulate negative log probability (we want to minimize)\n",
        "                new_beams.append((new_seq, new_score))\n",
        "\n",
        "        # Select top k sequences based on cumulative score\n",
        "        beams = sorted(new_beams, key=lambda x: x[1])[:beam_width]\n",
        "\n",
        "        # Check if all beams ended with eos_token\n",
        "        if all(seq[-1].item() == eos_token for seq, _ in beams):\n",
        "            break\n",
        "\n",
        "    # Return the best beam\n",
        "    best_sequence = beams[0][0]\n",
        "    return best_sequence\n",
        "\n",
        "def evaluate_translation(model, test_loader, src_vocab, tgt_vocab, device):\n",
        "    model.eval()\n",
        "    predictions, references = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in test_loader:\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "\n",
        "            # Generate translation output using beam search\n",
        "            output_sequence = generate_translation(model, src, src_vocab, tgt_vocab, device=device)\n",
        "\n",
        "            # Decode predicted output and reference output (target sequence)\n",
        "            pred_text = [tgt_vocab.itos[i] for i in output_sequence.tolist() if tgt_vocab.itos[i] != \"<pad>\"]\n",
        "            ref_text = [tgt_vocab.itos[i] for i in tgt[0].tolist() if tgt_vocab.itos[i] != \"<pad>\"]\n",
        "\n",
        "            predictions.append(\" \".join(pred_text))\n",
        "            references.append([\" \".join(ref_text)])\n",
        "\n",
        "    # Compute BLEU score using sacrebleu\n",
        "    bleu = sacrebleu.corpus_bleu(predictions, references)\n",
        "\n",
        "    # Print prediction and reference pairs\n",
        "    for i, (pred, ref) in enumerate(zip(predictions, references)):\n",
        "        print(f\"\\n[{i+1}]\")\n",
        "        print(f\"Prediction: {pred}\")\n",
        "        print(f\"Reference : {ref[0]}\")\n",
        "\n",
        "    # Output the BLEU score\n",
        "    print(f\"\\nCorpus BLEU score: {bleu.score:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:24.538837Z",
          "iopub.execute_input": "2025-04-25T16:28:24.539051Z",
          "iopub.status.idle": "2025-04-25T16:28:24.548561Z",
          "shell.execute_reply.started": "2025-04-25T16:28:24.539035Z",
          "shell.execute_reply": "2025-04-25T16:28:24.547889Z"
        },
        "id": "cPnHFY8K1PJP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_translation(model, test_loader, src_vocab, tgt_vocab, device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:24.549247Z",
          "iopub.execute_input": "2025-04-25T16:28:24.549497Z",
          "iopub.status.idle": "2025-04-25T16:28:24.743199Z",
          "shell.execute_reply.started": "2025-04-25T16:28:24.549482Z",
          "shell.execute_reply": "2025-04-25T16:28:24.742626Z"
        },
        "id": "DRmmwmZz1PJP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_translation(model, test_loader, src_vocab, tgt_vocab, device):\n",
        "    model.eval()\n",
        "    predictions, references = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in test_loader:\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "\n",
        "            # Generate translation output for the current test example\n",
        "            tgt_input = torch.full((1, 1), tgt_vocab.stoi[\"<sos>\"], dtype=torch.long).to(device)\n",
        "            output_sentence = []\n",
        "\n",
        "            for _ in range(20):  # max length\n",
        "                logits = model(src, tgt_input)\n",
        "                next_token = logits[:, -1, :].argmax(-1).unsqueeze(1)\n",
        "                tgt_input = torch.cat([tgt_input, next_token], dim=1)\n",
        "\n",
        "                if next_token.item() == tgt_vocab.stoi[\"<eos>\"]:\n",
        "                    break\n",
        "                output_sentence.append(next_token.item())\n",
        "\n",
        "            # Decode predicted output and reference output (target sequence)\n",
        "            pred_text = tgt_vocab.decode(output_sentence)\n",
        "            ref_text = tgt_vocab.decode(tgt[0].tolist())\n",
        "\n",
        "            # Remove <pad> tokens from reference and prediction for BLEU calculation\n",
        "            pred_text = [tgt_vocab.itos[i] for i in output_sentence if tgt_vocab.itos[i] != \"<pad>\"]\n",
        "            ref_text = [tgt_vocab.itos[i] for i in tgt[0].tolist() if tgt_vocab.itos[i] != \"<pad>\"]\n",
        "\n",
        "            predictions.append(\" \".join(pred_text))\n",
        "            references.append([\" \".join(ref_text)])\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(predictions, references)\n",
        "    for i, (pred, ref) in enumerate(zip(predictions, references)):\n",
        "        print(f\"\\n[{i+1}]\")\n",
        "        print(f\"Prediction: {pred}\")\n",
        "        print(f\"Reference : {ref[0]}\")\n",
        "\n",
        "    print(f\"\\nCorpus BLEU score: {bleu.score:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:24.743935Z",
          "iopub.execute_input": "2025-04-25T16:28:24.744196Z",
          "iopub.status.idle": "2025-04-25T16:28:24.751596Z",
          "shell.execute_reply.started": "2025-04-25T16:28:24.74417Z",
          "shell.execute_reply": "2025-04-25T16:28:24.750989Z"
        },
        "id": "oRNwKxz71PJP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------HYBRID EMBEDDINGS"
      ],
      "metadata": {
        "id": "QH3sBsFR1PJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class PhonemeMorphologyHybridModel(nn.Module):\n",
        "    def __init__(self, vocab_size, phoneme_emb_dim, morphology_emb_dim, embedding_dim, hidden_dim, bert_model_name=\"bert-base-uncased\"):\n",
        "        super(PhonemeMorphologyHybridModel, self).__init__()\n",
        "\n",
        "        # Word embedding layer (e.g., GloVe, FastText)\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Phoneme embedding layer\n",
        "        self.phoneme_embeddings = nn.Embedding(vocab_size, phoneme_emb_dim)\n",
        "\n",
        "        # Morphology-aware embedding layer\n",
        "        self.morphology_embeddings = nn.Embedding(vocab_size, morphology_emb_dim)\n",
        "\n",
        "        # BERT model for contextual embeddings\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "\n",
        "        # LSTM encoder-decoder\n",
        "        self.encoder = nn.LSTM(input_size=embedding_dim + phoneme_emb_dim + morphology_emb_dim + 768,  # Word + Phoneme + Morphology + BERT embeddings\n",
        "                               hidden_size=hidden_dim,\n",
        "                               num_layers=2,\n",
        "                               batch_first=True)\n",
        "\n",
        "        self.decoder = nn.LSTM(input_size=hidden_dim,\n",
        "                               hidden_size=hidden_dim,\n",
        "                               num_layers=2,\n",
        "                               batch_first=True)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Word-level embeddings\n",
        "        word_embeddings = self.word_embeddings(src)\n",
        "\n",
        "        # Phoneme embeddings\n",
        "        phoneme_embeddings = self.phoneme_embeddings(src)\n",
        "\n",
        "        # Morphology-aware embeddings\n",
        "        morphology_embeddings = self.morphology_embeddings(src)\n",
        "\n",
        "        # Get BERT contextual embeddings (assuming src is already tokenized)\n",
        "        bert_inputs = self.bert(input_ids=src)[0]  # Output embeddings from BERT\n",
        "\n",
        "        # Combine embeddings: Concatenate word, phoneme, morphology, and BERT embeddings\n",
        "        combined_embeddings = torch.cat((word_embeddings, phoneme_embeddings, morphology_embeddings, bert_inputs), dim=-1)\n",
        "\n",
        "        # Pass combined embeddings through the encoder and decoder\n",
        "        encoder_output, (hidden, cell) = self.encoder(combined_embeddings)\n",
        "        decoder_output, _ = self.decoder(tgt, (hidden, cell))\n",
        "\n",
        "        # Output predictions\n",
        "        output = self.fc_out(decoder_output)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Example of how to use the model\n",
        "vocab_size = 10000  # Adjust based on your data\n",
        "phoneme_emb_dim = 50  # Dimensionality of phoneme embeddings\n",
        "morphology_emb_dim = 100  # Dimensionality of morphology-aware embeddings\n",
        "embedding_dim = 300  # For GloVe or other pre-trained embeddings\n",
        "hidden_dim = 512\n",
        "\n",
        "model = PhonemeMorphologyHybridModel(vocab_size, phoneme_emb_dim, morphology_emb_dim, embedding_dim, hidden_dim)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:24.75251Z",
          "iopub.execute_input": "2025-04-25T16:28:24.752739Z",
          "iopub.status.idle": "2025-04-25T16:28:27.602199Z",
          "shell.execute_reply.started": "2025-04-25T16:28:24.752724Z",
          "shell.execute_reply": "2025-04-25T16:28:27.601512Z"
        },
        "id": "QMsRNa631PJP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_translation(model, test_loader, device=torch.device(\"cuda\")):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for batch in test_loader:\n",
        "        # Assuming the DataLoader yields a tuple (src_indices, phoneme_indices, morphology_indices, tgt_indices)\n",
        "        # If not, you will need to update the dataset to include phoneme_indices and morphology_indices\n",
        "        if len(batch) == 2:  # If batch contains only source and target indices\n",
        "            src_indices, tgt_indices = batch\n",
        "            phoneme_indices = None  # Replace with actual phoneme indices if available\n",
        "            morphology_indices = None  # Replace with actual morphology indices if available\n",
        "        else:\n",
        "            src_indices, phoneme_indices, morphology_indices, tgt_indices = batch\n",
        "\n",
        "        src_indices, phoneme_indices, morphology_indices, tgt_indices = \\\n",
        "            src_indices.to(device), phoneme_indices.to(device), morphology_indices.to(device), tgt_indices.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Forward pass through the model\n",
        "            output = model(src_indices, phoneme_indices, morphology_indices, tgt_indices)\n",
        "\n",
        "            # Get the predicted translation (argmax over output)\n",
        "            predicted_indices = output.argmax(dim=-1)\n",
        "\n",
        "            # Convert predicted indices to words (this part depends on how you map indices to words)\n",
        "            predicted_words = [tgt_vocab.itos[idx] for idx in predicted_indices.squeeze().cpu().numpy()]\n",
        "            reference_words = [tgt_vocab.itos[idx] for idx in tgt_indices.squeeze().cpu().numpy()]\n",
        "\n",
        "            predictions.append(predicted_words)\n",
        "            references.append([reference_words])  # BLEU requires references to be a list of lists\n",
        "\n",
        "    # Compute BLEU score (corpus-wide)\n",
        "    bleu_score = corpus_bleu(references, predictions)\n",
        "    print(f\"Corpus BLEU score: {bleu_score * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.48838Z",
          "iopub.status.idle": "2025-04-25T16:28:28.48872Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.488548Z",
          "shell.execute_reply": "2025-04-25T16:28:28.488563Z"
        },
        "id": "252XoLlJ1PJQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_data, phoneme_data, morphology_data, tgt_data):\n",
        "        self.src_data = src_data\n",
        "        self.phoneme_data = phoneme_data\n",
        "        self.morphology_data = morphology_data\n",
        "        self.tgt_data = tgt_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_idx = self.src_data[idx]\n",
        "        phoneme_idx = self.phoneme_data[idx]\n",
        "        morphology_idx = self.morphology_data[idx]\n",
        "        tgt_idx = self.tgt_data[idx]\n",
        "        return src_idx, phoneme_idx, morphology_idx, tgt_idx\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.489885Z",
          "iopub.status.idle": "2025-04-25T16:28:28.490221Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.490043Z",
          "shell.execute_reply": "2025-04-25T16:28:28.490057Z"
        },
        "id": "g3g6tjnT1PJQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the data loaded as numpy arrays or lists\n",
        "test_dataset = TranslationDataset(src_data, phoneme_data, morphology_data, tgt_data)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.492353Z",
          "iopub.status.idle": "2025-04-25T16:28:28.492598Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.492489Z",
          "shell.execute_reply": "2025-04-25T16:28:28.492502Z"
        },
        "id": "gi9zdNA21PJQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------TESTING 5"
      ],
      "metadata": {
        "id": "uVLefUgD1PJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example vocab dictionary with '<unk>' token added\n",
        "src_vocab = {\n",
        "    '<sos>': 0,\n",
        "    '<eos>': 1,\n",
        "    'i': 2,\n",
        "    'saw': 3,\n",
        "    'her': 4,\n",
        "    'at': 5,\n",
        "    'the': 6,\n",
        "    'market': 7,\n",
        "    '<unk>': 8  # Added the <unk> token for unknown words\n",
        "}\n",
        "\n",
        "tgt_vocab = {\n",
        "    '<sos>': 0,\n",
        "    '<eos>': 1,\n",
        "    'yo': 2,\n",
        "    'fui': 3,\n",
        "    'a': 4,\n",
        "    'la': 5,\n",
        "    'tienda': 6,\n",
        "    '<unk>': 7  # Added the <unk> token for unknown words\n",
        "}\n",
        "\n",
        "# Example source and target data\n",
        "src_data = [\n",
        "    ['i', 'saw', 'her', 'at', 'the', 'market'],\n",
        "    ['are', 'you', 'going', 'to', 'the', 'store']\n",
        "]\n",
        "\n",
        "tgt_data = [\n",
        "    ['yo', 'fui', 'a', 'la', 'tienda'],\n",
        "    ['estás', 'yendo', 'a', 'la', 'tienda']\n",
        "]\n",
        "\n",
        "# Convert sentences to indices using the vocab dictionaries\n",
        "src_data_indices = [[src_vocab.get(word, src_vocab['<unk>']) for word in sentence] for sentence in src_data]\n",
        "tgt_data_indices = [[tgt_vocab.get(word, tgt_vocab['<unk>']) for word in sentence] for sentence in tgt_data]\n",
        "\n",
        "print(\"Source Data Indices:\", src_data_indices)\n",
        "print(\"Target Data Indices:\", tgt_data_indices)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.493547Z",
          "iopub.status.idle": "2025-04-25T16:28:28.493753Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.493654Z",
          "shell.execute_reply": "2025-04-25T16:28:28.493663Z"
        },
        "id": "_KtypINv1PJQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a vocab object that maps words to indices\n",
        "# Example vocab dictionary\n",
        "src_vocab = {'<sos>': 0, '<eos>': 1, 'i': 2, 'saw': 3, 'her': 4, 'at': 5, 'the': 6, 'market': 7, ...}\n",
        "tgt_vocab = {'<sos>': 0, '<eos>': 1, 'yo': 2, 'fui': 3, 'a': 4, 'la': 5, 'tienda': 6, ...}\n",
        "\n",
        "# Convert sentences to indices\n",
        "src_data_indices = [[src_vocab[word] for word in sentence] for sentence in src_data]\n",
        "tgt_data_indices = [[tgt_vocab[word] for word in sentence] for sentence in tgt_data]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.495424Z",
          "iopub.status.idle": "2025-04-25T16:28:28.495728Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.495581Z",
          "shell.execute_reply": "2025-04-25T16:28:28.495594Z"
        },
        "id": "AUMinMcE1PJQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the TranslationDataset class\n",
        "class TranslationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_data, phoneme_data, morphology_data, tgt_data):\n",
        "        self.src_data = src_data\n",
        "        self.phoneme_data = phoneme_data\n",
        "        self.morphology_data = morphology_data\n",
        "        self.tgt_data = tgt_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_idx = self.src_data[idx]\n",
        "        phoneme_idx = self.phoneme_data[idx]\n",
        "        morphology_idx = self.morphology_data[idx]\n",
        "        tgt_idx = self.tgt_data[idx]\n",
        "        return src_idx, phoneme_idx, morphology_idx, tgt_idx\n",
        "\n",
        "# Assuming you have the data loaded and converted to indices\n",
        "test_dataset = TranslationDataset(src_data_indices, phoneme_data, morphology_data, tgt_data_indices)\n",
        "\n",
        "# Create the DataLoader\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.496722Z",
          "iopub.status.idle": "2025-04-25T16:28:28.497138Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.496976Z",
          "shell.execute_reply": "2025-04-25T16:28:28.496992Z"
        },
        "id": "RmbG-FGV1PJQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your model is already defined and loaded\n",
        "evaluate_translation(model, test_loader, device=torch.device(\"cuda\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.498236Z",
          "iopub.status.idle": "2025-04-25T16:28:28.498488Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.498386Z",
          "shell.execute_reply": "2025-04-25T16:28:28.498396Z"
        },
        "id": "zdE3BUX41PJR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, src, tgt):\n",
        "    # Word-level embeddings\n",
        "    word_embeddings = self.word_embeddings(src)\n",
        "\n",
        "    # Phoneme embeddings (if applicable)\n",
        "    phoneme_embeddings = self.phoneme_embeddings(src)\n",
        "\n",
        "    # Combine word and phoneme embeddings\n",
        "    combined_embeddings = torch.cat([word_embeddings, phoneme_embeddings], dim=-1)\n",
        "\n",
        "    # Pass combined embeddings through the encoder\n",
        "    encoder_output, (hidden, cell) = self.encoder(combined_embeddings)\n",
        "\n",
        "    # Ensure hidden and cell states are in the correct shape\n",
        "    batch_size = combined_embeddings.size(0)\n",
        "\n",
        "    # For a batch size of 1, remove the unnecessary dimensions to make hidden/cell 2D\n",
        "    if batch_size == 1:\n",
        "        hidden = hidden.squeeze(0)  # Remove the first dimension if batch size is 1\n",
        "        cell = cell.squeeze(0)  # Remove the first dimension if batch size is 1\n",
        "    else:\n",
        "        # Otherwise, make sure the states are 2D (batch_size, hidden_size)\n",
        "        hidden = hidden.view(batch_size, self.hidden_size)  # Ensure it's 2D\n",
        "        cell = cell.view(batch_size, self.hidden_size)  # Ensure it's 2D\n",
        "\n",
        "    # Pass the hidden and cell states to the decoder\n",
        "    decoder_output, _ = self.decoder(tgt, (hidden, cell))\n",
        "\n",
        "    # Output predictions\n",
        "    return decoder_output\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.500305Z",
          "iopub.status.idle": "2025-04-25T16:28:28.500723Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.500551Z",
          "shell.execute_reply": "2025-04-25T16:28:28.500566Z"
        },
        "id": "bPwyixI41PJR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Custom Dataset for Translation\n",
        "class TranslationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_data, tgt_data):\n",
        "        self.src_data = src_data\n",
        "        self.tgt_data = tgt_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.src_data[idx], self.tgt_data[idx]\n",
        "\n",
        "# Custom collate function to pad sequences\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "\n",
        "    # Pad the source and target sequences\n",
        "    src_padded = pad_sequence([torch.tensor(seq) for seq in src_batch], padding_value=src_vocab['<unk>'], batch_first=True)\n",
        "    tgt_padded = pad_sequence([torch.tensor(seq) for seq in tgt_batch], padding_value=tgt_vocab['<unk>'], batch_first=True)\n",
        "\n",
        "    return src_padded, tgt_padded\n",
        "\n",
        "# Example data\n",
        "src_data = [\n",
        "    ['i', 'saw', 'her', 'at', 'the', 'market'],\n",
        "    ['are', 'you', 'going', 'to', 'the', 'store']\n",
        "]\n",
        "\n",
        "tgt_data = [\n",
        "    ['yo', 'fui', 'a', 'la', 'tienda'],\n",
        "    ['estás', 'yendo', 'a', 'la', 'tienda']\n",
        "]\n",
        "\n",
        "# Convert sentences to indices using vocab dictionaries\n",
        "src_data_indices = [[src_vocab.get(word, src_vocab['<unk>']) for word in sentence] for sentence in src_data]\n",
        "tgt_data_indices = [[tgt_vocab.get(word, tgt_vocab['<unk>']) for word in sentence] for sentence in tgt_data]\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = TranslationDataset(src_data_indices, tgt_data_indices)\n",
        "test_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn, shuffle=False)\n",
        "\n",
        "# Define the evaluate_translation function\n",
        "def evaluate_translation(model, test_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # Move the model to the correct device (CUDA)\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src_indices, tgt_indices in test_loader:\n",
        "            # Move input tensors to the same device as the model\n",
        "            src_indices, tgt_indices = src_indices.to(device), tgt_indices.to(device)\n",
        "\n",
        "            # Forward pass (adjust based on your model architecture)\n",
        "            output = model(src_indices, tgt_indices)  # Assuming your model takes src and tgt\n",
        "            # Assuming loss function and target processing is done correctly\n",
        "            loss = loss_function(output, tgt_indices)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    # Print the average loss\n",
        "    print(f\"Total loss: {total_loss / len(test_loader)}\")\n",
        "\n",
        "# Assuming your model is already defined and loaded\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "evaluate_translation(model, test_loader, device=device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-25T16:28:28.502069Z",
          "iopub.status.idle": "2025-04-25T16:28:28.502394Z",
          "shell.execute_reply.started": "2025-04-25T16:28:28.502233Z",
          "shell.execute_reply": "2025-04-25T16:28:28.502248Z"
        },
        "id": "ZbETWT2d1PJR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "_lfKzZ7l1PJR"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}